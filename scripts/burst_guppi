#! /usr/bin/python
"""Search guppi files for fast radio bursts.
"""

import time
import argparse
from os import path
import logging
import glob
import cProfile, pstats, StringIO

import numpy as np
import watchdog.observers
import watchdog.events

logger = logging.getLogger(__name__)
#logger.setLevel(logging.INFO)
#logger.addHandler(logging.StreamHandler())


try:
    from mpi4py import MPI
    mpi_size = MPI.COMM_WORLD.Get_size()
    mpi_rank = MPI.COMM_WORLD.Get_rank()
    logformat = 'Rank%d' % mpi_rank
    logformat += ':%(levelname)s:%(name)s:%(message)s'
    logging.basicConfig(format=logformat, level=logging.INFO)
    logger.info("MPI available. Process size is %d. My rank is %d."
                % (mpi_size, mpi_rank))
except ImportError:
    mpi_size = 1
    mpi_rank = 0
    logging.basicConfig(level=logging.INFO)
    logger.info("MPI not available.")


# Command line arguments.
parser = argparse.ArgumentParser(description='Search GUPPI data for FRBs.')
parser.add_argument(
        "files",
        metavar="GUPPI_files",
        type=str,
        nargs='+',
        help="GUPPI PSRFITS files to search.",
        )
parser.add_argument(
        '-p', '--show_plot',
        type=bool,
        default=False
        )
parser.add_argument(
        '--disp_ind_search',
        type=float,
        default=None,
        nargs=3,
        metavar=('min', 'max', 'ntrail'),
        help="Dispersion index search parameters (eg. '1. 5. 4')"
        )
parser.add_argument(
        '--spec_ind_search',
        type=float,
        default=None,
        nargs=3,
        metavar=('min', 'max', 'ntrail'),
        help="Spectral index search parameters (eg. '-5. 5. 3')"
        )
parser.add_argument(
        '--max_dm',
        type=float,
        default=2000.0
        )
parser.add_argument(
        '--simulate',
        type=float,
        default=None,
        nargs=2,
        metavar=('rate', 'max_fluence'),
        help="Simulation event injection parameters. Specify both"
        " an average rate (per second) and max fluence (in units"
        " T_sys seconds). Eg. '0.01 0.0001'."
        )
parser.add_argument(
        '--scrunch',
        action='store_true',
        default=False,
        help="Use scrunching to achieve max DM."
        )
parser.add_argument(
        '--profile',
        action='store_true',
        default=False,
        help='Profile computation performance and print results.',
        )
parser.add_argument(
        '--watch',
        action='store_true',
        default=False,
        help="Only process new files appearing, in real time."
        " Remember to wrap your 'files' argument - which specifies"
        " a matching patern for new file - in quotes to prevent your"
        " shell from expanding the glob.",
        )


def setup_searchers(filename, args):

    search_pars = {}
    if args.disp_ind_search is not None:
        search_pars['disp_ind_search'] = True
        search_pars['disp_ind_min'] =  args.disp_ind_search[0]
        search_pars['disp_ind_max'] =  args.disp_ind_search[1]
        search_pars['disp_ind_samples'] = int(args.disp_ind_search[2])
    if args.spec_ind_search is not None:
        search_pars['spec_ind_search'] = True
        search_pars['spec_ind_min'] =  args.spec_ind_search[0]
        search_pars['spec_ind_max'] =  args.spec_ind_search[1]
        search_pars['spec_ind_samples'] = int(args.spec_ind_search[2])
    if args.simulate is not None:
        search_pars["simulate"] = True
        search_pars["simulate_rate"] = args.simulate[0]
        search_pars["simulate_fluence"] = args.simulate[1]
    if args.scrunch:
        search_pars["max_dm"] = -1.9
        search_pars["scrunch"] = 1
    else:
        search_pars["max_dm"] = args.max_dm

    act_str = 'save_plot_dm,print'
    if args.show_plot:
        act_str = act_str + ',show_plot_dm'
    logger.info('Doing actions: %s' % act_str)

    searchers = []
    while True:
        try:
            s = guppi.Manager(filename,
                              **dict(search_pars))
        except IOError as e:
            logging.error("Rank %d, file can't be opened %s."
                    % (mpi_rank, filename))
            break

        s.set_trigger_action(act_str)

        searchers.append(s)
        if s.max_dm >= args.max_dm:
            break
        else:
            search_pars["min_search_dm"] = s.max_dm
            search_pars["scrunch"] *= 2
    if args.scrunch:
        n_searchers = len(searchers)
        logger.info("Covered DM range with 2^%d scrunching." % n_searchers)
    return searchers


# What to do with new files.
class NewFileHandler(watchdog.events.PatternMatchingEventHandler):

    def __init__(self, patterns, args):
        watchdog.events.PatternMatchingEventHandler.__init__(
                self,
                patterns=patterns,
                case_sensitive=True,
                )

        self._args = args
        self._nfiles_discovered = 0

    def on_created(self, event):
        if event.is_directory:
            return

        print 'FILE'

        if self._nfiles_discovered % mpi_size == mpi_rank:
            filename = event.src_path
            filename = path.abspath(filename)
            logger.info("File %s." % filename)
            searchers = setup_searchers(filename, self._args)

            searchers[0].wait_next_block()
            while searchers[0].wait_next_block():
                for s in searchers:
                    s.wait_next_block()
                    s.process_next_block()
            for s in searchers:
                s.process_all()

        self._nfiles_discovered += 1



if __name__ == "__main__":
    args = parser.parse_args()

    if not args.show_plot:
        # Configure matplotlib to not need X.
        import matplotlib as mpl
        mpl.use('Agg')

    # Must be imported after choosing mpl backend.
    from burst_search import guppi

    if not args.watch:
        files = args.files
        print files
        if len(files) == 1:
            files = glob.glob(files[0])

        if mpi_size > 1:
            files = sorted(files)
        else:
            files = files

        for filename in files[mpi_rank::mpi_size]:
            logger.info("File %s." % filename)
            searchers = setup_searchers(filename, args)
            for s in searchers:
                if args.profile:
                    pr = cProfile.Profile()
                    pr.enable()

                s.process_all()

                if args.profile:
                    pr.disable()
                    s = StringIO.StringIO()
                    sortby = 'cumulative'
                    ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
                    ps.print_stats()
                    print '\n'.join(s.getvalue().split('\n')[:200])
                    #out_file.close()
    else:
        if len(args.files) != 1:
            raise ValueError("Can only supply one file pattern in watch mode")
        directory, pattern = path.split(args.files[0])
        directory = path.abspath(directory)
        event_handler = NewFileHandler(args.files[0], args)
        observer = watchdog.observers.Observer()
        observer.schedule(event_handler, directory,
                          recursive=False)
        logger.info("Watching %s for new files matching %s."
                    % (directory,pattern))
        try:
            while True:
                time.sleep(1)
        except KeyboardInterrupt:
            observer.stop()
        observer.join()

